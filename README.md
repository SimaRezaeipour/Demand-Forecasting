# Demand-Forecasting
Demand Forecasting of new products using product descriptions and LLMs
It is challenging to predict the demand for new products due to the unavailability of historical sales data. A company's operational decisions depend on accurate forecasting. Poor forecasting can damage a company's reputation and lead to financial problems. Demand forecasting has traditionally relied on historical sales data without considering the product description as a feature. This study proposes a novel approach by incorporating product descriptions as an additional feature to improve new product sales forecasting. This approach involves clustering products based on the similarity of their descriptions and only considers time series data from similar products to predict demand. The product descriptions are encoded using different language models and embeddings such as RoBERTa, DistilBERT and SimCSE. We employed two commonly used methods for dimensionality reduction, namely UMAP and TSNE, to transform encoded product descriptions into a 2D space. Subsequently, we applied either HDBSCAN or Kmeans clustering algorithms to group them together. A Top2Vec model is trained on the product descriptions within each cluster, and the resulting topics were utilized as cluster descriptions as a novel feature in our model. We computed the mean of the embeddings for each cluster/topic and employed cosine similarity to allocate the description of each new product to a corresponding cluster. The forecast is made based on historical sales data of previously introduced (current) products and new products, using state-of-the-art forecasting models including Light Gradient Boosting Machine (LightGBM) regressor, Catboost, and Facebook Prophet. According to the study, employing language models to cluster current product descriptions and allocate new products to those clusters enhances the accuracy of sales forecasting of new products. The research employs a publicly available dataset of sales data from an online retailer based in the UK, obtained from Kaggle, and evaluates the performance using evaluation metrics such as Root Mean Squared Error (RMSE), Weighted Mean Absolute Percentage Error (WMAPE), Bias, and standard deviation. 
